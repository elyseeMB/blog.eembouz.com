<!DOCTYPE html><html lang="fr"> <head><title>Convolutional Neural Networks | Blog</title><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="description" content="A Convolutional Neural Network (CNN) is a type of supervised deep learning algorithm that confers upon computers a form of 'vision': it can analyze and recognize objects in the visual world."><link rel="canonical" href="https://blog.eembouz.com/en/articles/convolutional-neural-networks/"><meta name="author" content="elysee"><meta property="article:published_time" content="2025-08-12T00:00:00.000Z"><link rel="icon" type="image/png" href="https://blog.eembouz.com/favicon-512.png" sizes="512x512"><link rel="icon" type="image/svg+xml" href="https://blog.eembouz.com/favicon.svg"><link rel="apple-touch-icon" href="https://blog.eembouz.com/apple-touch-icon.png"><link rel="manifest" href="https://blog.eembouz.com/site.webmanifest"><link rel="sitemap" href="https://blog.eembouz.com/sitemap-index.xml"><link rel="icon" type="image/png" href="https://blog.eembouz.com/favicon-96x96.png" sizes="96x96"><link rel="apple-touch-icon" sizes="180x180" href="https://blog.eembouz.com/apple-touch-icon.png"><meta name="theme-color" content="#1e1e1e"><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link href="https://fonts.googleapis.com/css2?family=Inter:ital,opsz,wght@0,14..32,100..900;1,14..32,100..900&family=Work+Sans:ital,wght@0,100..900;1,100..900&display=swap" rel="stylesheet"><meta property="og:type" content="article"><meta property="og:site_name" content="Elysee-Mboussa"><meta property="og:title" content="Convolutional Neural Networks | Blog"><meta property="og:type" content="website"><meta property="og:description" content="A Convolutional Neural Network (CNN) is a type of supervised deep learning algorithm that confers upon computers a form of 'vision': it can analyze and recognize objects in the visual world."><meta property="og:image" content="/iclh-diagram-convolutional-neural-networks.png"><meta property="og:url" content="https://blog.eembouz.com/en/articles/convolutional-neural-networks/"><meta name="robots" content="index, follow"><meta name="google-site-verification" content="hyeUNyeanb3BYVbCmMJKMIiXusraMSWPSCNMBn83Sk8"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:title" content="Convolutional Neural Networks | Blog"><meta name="twitter:description" content="A Convolutional Neural Network (CNN) is a type of supervised deep learning algorithm that confers upon computers a form of 'vision': it can analyze and recognize objects in the visual world."><meta name="twitter:image" content="/iclh-diagram-convolutional-neural-networks.png"><meta name="twitter:site" content="@EmmanuelitoElysee"><script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "WebSite",
    "name": "Emmanuelito elysee",
    "url": "https://blog.eembouz.com",
    "potentialAction": {
      "@type": "SearchAction",
      "target": "https://blog.eembouz.com",
      "query-input": "required name=search_term_string"
    }
  }
</script><script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "Emmanuelito Elysee",
    "url": "https://blog.eembouz.com/",
    "logo": "https://blog.eembouz.com/favicon-512.png"
  }
</script><script defer src="https://umami-proxy.mboussaemmanuelito.workers.dev/script.js" data-website-id="074cd697-7046-4949-bb7e-9c9be2a2a455" data-host-url="https://umami-proxy.mboussaemmanuelito.workers.dev"></script><script type="module" src="/_astro/Scripts.astro_astro_type_script_index_0_lang.enUXedja.js"></script><script data-default-theme="auto">
  window.theme ??= (() => {
    const defaultTheme =
      document.currentScript.getAttribute("data-default-theme");
    const storageKey = "theme";
    const store =
      typeof localStorage !== "undefined"
        ? localStorage
        : { getItem: () => null, setItem: () => {} };

    const mediaMatcher = window.matchMedia("(prefers-color-scheme: light)");
    let systemTheme = mediaMatcher.matches ? "light" : "dark";
    mediaMatcher.addEventListener("change", (event) => {
      systemTheme = event.matches ? "light" : "dark";
      applyTheme(getTheme());
    });

    function applyTheme(theme) {
      const resolvedTheme = theme === "auto" ? systemTheme : theme;
      document.documentElement.dataset.theme = resolvedTheme;
      document.documentElement.style.colorScheme = resolvedTheme;
      document.dispatchEvent(
        new CustomEvent("theme-changed", {
          detail: { theme, systemTheme, defaultTheme },
        })
      );
    }

    function setTheme(theme = defaultTheme) {
      store.setItem(storageKey, theme);
      applyTheme(theme);
    }

    function getTheme() {
      return store.getItem(storageKey) || defaultTheme;
    }

    function getSystemTheme() {
      return systemTheme;
    }

    function getDefaultTheme() {
      return defaultTheme;
    }

    return { setTheme, getTheme, getSystemTheme, getDefaultTheme };
  })();
  theme.setTheme(theme.getTheme());
</script> <script type="module">document.addEventListener("astro:after-swap",()=>window.theme.setTheme(window.theme.getTheme()));</script><style>.content[data-astro-cid-m3uvi3ai]{margin:0 auto;padding-bottom:5rem}.info[data-astro-cid-vxl4wgev]{font-family:Work Sans,sans-serif}.container[data-astro-cid-fv4hxrc2],.wrapper-content[data-astro-cid-fv4hxrc2]{overflow:visible}.article__paragraph[data-astro-cid-fv4hxrc2]{padding-block:1rem}.description[data-astro-cid-fv4hxrc2]{padding-block:3rem}.info[data-astro-cid-fv4hxrc2]{display:grid;grid-template-columns:1fr;gap:.5rem}.wrapper-content[data-astro-cid-fv4hxrc2]>[data-astro-cid-fv4hxrc2]{min-width:0}.wrapper-content[data-astro-cid-fv4hxrc2]{display:block}.wrapper-outline[data-astro-cid-fv4hxrc2]{display:none}@media screen and (min-width:1200px){.wrapper-content[data-astro-cid-fv4hxrc2]{width:100%;display:flex;justify-content:space-between;gap:5rem;padding:0}.wrapper-outline[data-astro-cid-fv4hxrc2]{display:block;margin-bottom:5rem;justify-self:end}}.content[data-astro-cid-fv4hxrc2]{padding-bottom:5rem}.cover[data-astro-cid-fv4hxrc2]{padding-bottom:5rem;width:100%}.meta[data-astro-cid-fv4hxrc2]{display:flex;flex-direction:column;font-size:.9rem;gap:.5rem;padding-bottom:4rem;font-family:JetBrains Mono!important;>[data-astro-cid-fv4hxrc2]{font-family:JetBrains Mono!important;letter-spacing:-.5px;color:var(--color-secondary)}}@media screen and (max-width:590px){.container-narrow[data-astro-cid-fv4hxrc2] .info[data-astro-cid-fv4hxrc2] .tags[data-astro-cid-fv4hxrc2]{align-items:flex-start;flex-direction:column}}@media screen and (min-width:1300px){.heading[data-astro-cid-fv4hxrc2]{img{max-height:500px}}}
</style>
<link rel="stylesheet" href="/_astro/505.AYIiQRes.css"></head> <body> <div class="effect-blur pointer-events-none fixed inset-0 z-50 h-10 w-screen md:h-16"></div> <div class="from-background pointer-events-none fixed inset-0 z-50 h-4 w-screen bg-gradient-to-b to-transparent"></div> <header class="fixed left-0 top-0 text-sm w-full uppercase" data-astro-cid-6sev2il6> <div class="container" data-astro-cid-6sev2il6> <div class="flex" data-astro-cid-6sev2il6> <div class="logo" data-astro-cid-6sev2il6> <a href="https://blog.eembouz.com/en">  <svg width="40" height="40" id="logo" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 12" data-astro-cid-6sev2il6> <defs data-astro-cid-6sev2il6> <style>
                .cls-1,
                .cls-2 {
                  stroke-width: 0px;
                }

                .cls-2 {
                  fill: #007aec;
                }
              </style> </defs> <circle class="cls-2" cx="6" cy="6" r="5.5" data-astro-cid-6sev2il6></circle> <path class="cls-1" d="m6,1c2.76,0,5,2.24,5,5s-2.24,5-5,5S1,8.76,1,6,3.24,1,6,1m0-1C2.69,0,0,2.69,0,6s2.69,6,6,6,6-2.69,6-6S9.31,0,6,0h0Z" data-astro-cid-6sev2il6></path> </svg> </a> </div>  <ul class="flex-header actions" data-astro-cid-j2devmb2> <li class="btn btn-link" data-astro-cid-j2devmb2> <a href="https://eembouz.com" class="btn-click magnetic link-header" data-strength="25" data-strength-text="10" data-astro-cid-j2devmb2> <span class="btn-text" data-astro-cid-j2devmb2> <span class="btn-text-inner" data-astro-cid-j2devmb2>Portfolio</span> </span> </a> </li> <li class="btn btn-link" data-astro-cid-j2devmb2> <a href="/en/articles/" class="btn-click magnetic link-header" aria-current="page" class="aria-[current=page]:text-[var(--contrast)]! transition-colors duration-300" data-strength="25" data-strength-text="10" data-astro-cid-j2devmb2> <span class="btn-text" data-astro-cid-j2devmb2> <span class="btn-text-inner" data-astro-cid-j2devmb2>Lists</span> </span> </a> </li> </ul>  </div> </div> </header>   <div class="page-wrapper">  <section data-markdown class="w-full" data-astro-cid-fv4hxrc2> <div class="container medium" data-astro-cid-fv4hxrc2> <div class="info grid grid-cols-1 gap-8 md:grid-cols-2 lg:grid-cols-5 pb-10 lg:pb-[5rem]" data-astro-cid-vxl4wgev> <div class="info flex flex-col gap-4 md:col-span-2 lg:col-span-2 animate-blur-in">  <span class="relative text-sm uppercase flex items-center gap-2 before:content-[''] before:inset-0 before:w-2.5 before:h-2.5 before:bg-[var(--primary)] before:block"> Abstract </span> <h1 class="text-sm text-balance uppercase w-full lg:w-2/3" data-astro-cid-vxl4wgev> Convolutional Neural Networks </h1> <p class="uppercase text-[var(--color-secondary)] text-[0.7rem]" data-astro-cid-vxl4wgev> A Convolutional Neural Network (CNN) is a type of supervised deep learning algorithm that confers upon computers a form of &#39;vision&#39;: it can analyze and recognize objects in the visual world. </p>  </div> <div class="lg:col-start-4 lg:col-span-2 grid grid-cols-2" data-astro-cid-vxl4wgev> <div class="info flex flex-col gap-4 uppercase text-[0.7rem] animate-blur-in animation-delay-200">  <span class="relative text-sm uppercase flex items-center gap-2 before:content-[''] before:inset-0 before:w-2.5 before:h-2.5 before:bg-[var(--primary)] before:block"> Insights </span> <div class="flex flex-col items-start gap-1 text-[var(--color-secondary)]" data-astro-cid-vxl4wgev> <div class="flex items-center gap-2">  <span> Elysee </span> </div> <span> 8 min</span> <!-- 
<div class="animate-slide-in animation-delay-200">
  <Button>
    <span class="btn-click magnetic" data-strength="45" data-strength-text="25">
      <div class="btn-fill 0"></div>
      <span class="btn-text">
        <span class="btn-text-inner change">
          <span class="">
            <div class="flex items-center gap-2">
              <svg
                xmlns="http://www.w3.org/2000/svg"
                width="24"
                height="24"
                viewBox="0 0 24 24"
                fill="none"
                stroke="currentColor"
                stroke-width="2"
                stroke-linecap="round"
                stroke-linejoin="round"
                class="lucide lucide-timer-icon lucide-timer"
                ><line x1="10" x2="14" y1="2" y2="2"></line><line
                  x1="12"
                  x2="15"
                  y1="14"
                  y2="11"></line><circle cx="12" cy="14" r="8"></circle></svg
              >
              <span> {Math.ceil(time) + " " + "min"}</span>
            </div>
          </span>
        </span>
      </span>
    </span>
  </Button>
</div> --> <span class="uppercase" data-astro-cid-vxl4wgev>August 12, 2025</span> </div>  </div> <div class="info flex flex-col gap-4 animate-blur-in animation-delay-300">  <span class="relative text-sm uppercase flex items-center gap-2 before:content-[''] before:inset-0 before:w-2.5 before:h-2.5 before:bg-[var(--primary)] before:block"> Taxonomy </span> <div class="flex flex-col gap-1 uppercase text-[0.7rem] text-[var(--color-secondary)]" data-astro-cid-vxl4wgev> <div data-astro-cid-vxl4wgev>ia</div><div data-astro-cid-vxl4wgev>Deep learning</div> </div> </div> </div> </div>  </div> <div class="container medium" data-astro-cid-fv4hxrc2> <div class="heading" data-astro-cid-fv4hxrc2> <div class="cover animate-fade-in animation-delay-300" data-astro-cid-fv4hxrc2> <img src="/iclh-diagram-convolutional-neural-networks.png" class="w-full aspect-video h-auto object-cover" alt="" data-astro-cid-fv4hxrc2> </div> </div> </div> <div class="container medium" data-astro-cid-fv4hxrc2> <div class="m-auto content prose prose-sm lg:prose-lg prose-headings:font-normal prose-p:font-extralight prose-ul:font-extralight prose-ol:font-extralight prose-li:font-extralight prose-em:font-extralight prose-strong:font-extralight animate-blur-in animation-delay-300" data-astro-cid-m3uvi3ai>  <p><strong>From sports to medicine, transportation to security…</strong><br/>
Have you ever wondered how a surveillance camera manages to recognize a face in a crowd, how a medical scanner detects a concealed tumor, or how a system tracks a train’s trajectory with millimeter precision?</p>
<h2 id="introduction">Introduction</h2>
<p>A <strong>Convolutional Neural Network</strong> (<em>Convolutional Neural Network</em>, or CNN) is a type of supervised deep learning algorithm that confers upon computers a form of “vision”: it can analyze and recognize objects in the visual world.</p>
<p>The <strong>Convolutional Neural Network</strong> (<em>Convolutional Neural Network</em>, CNN), by analogy, refers to the functioning of biological neural networks and consequently constitutes an extension of the Artificial Neural Network (<em>Artificial Neural Network</em>, ANN). Its applications are primarily found in image recognition and analysis.</p>
<p>Building upon the principles of linear algebra, and more particularly on matrix manipulation, convolutional neural networks apply convolution and transformation operations to detect and extract pertinent patterns within an image.</p>
<h2 id="how-cnns-operate">How CNNs Operate</h2>
<p>The functioning of a <strong>Convolutional Neural Network</strong> (CNN) relies on an architecture composed of three principal layer types. These layers process spatially structured input data, such as images, audio spectrograms, or video sequences:</p>
<ul>
<li><strong>Convolutional layer</strong> (<em>Convolutional layer</em>)</li>
<li><strong>Pooling or subsampling layer</strong> (<em>Pooling layer</em>)</li>
<li><strong>Fully connected layer</strong> (<em>Fully connected layer</em>)</li>
</ul>
<h2 id="convolutional-layer"><strong>Convolutional Layer</strong></h2>
<p>The convolutional layer constitutes the network’s core, where the majority of computations are performed. Its operation requires components such as:</p>
<ul>
<li>Input data</li>
<li>Filter (kernel)</li>
<li>Feature map</li>
</ul>
<h3 id="operational-mechanism">Operational Mechanism:</h3>
<ul>
<li><strong>Convolution</strong> (dot product)</li>
<li><strong>ReLU</strong> (eliminates negative values)</li>
<li><strong>Pooling</strong> (dimensionality reduction)</li>
<li>Repeat these steps</li>
<li><strong>Final classification</strong></li>
</ul>
<p><strong>Input Data</strong>: Consider an input image of size 24×24 pixels, which will be transformed into a 3D pixel matrix corresponding to the respective number of pixels in the image. This means that the input is represented in height, width, and depth corresponding to the RGB characteristics of the image.</p>
<p><strong>Filter (kernel)</strong>: The filter is a weight matrix that traverses the image to detect shapes and characteristics. This process is known as the convolution operation.</p>
<ul>
<li>Contours</li>
<li>Lines</li>
<li>Textures</li>
<li>Geometric shapes</li>
<li>More complex characteristics in deeper layers</li>
</ul>
<p>Its size may vary, although by default it is 3×3, there exist 5×5, or 7×7 pixel filters. The <strong>receptive field</strong> corresponds to the input image area that influences an output neuron.</p>
<p>The filter is positioned on an image region and the dot product is calculated based on the input pixels and the filter. This value is then saved in a feature map. Subsequently, the filter is shifted by one stride, repeating the process until the entire pixel surface of the image has been processed.</p>
<p>Certain filter hyperparameters remain fixed during the process, however the <strong>weights</strong> are adjusted to maximize performance via backpropagation and gradient descent operations. Three critical hyperparameters exist that are paramount in obtaining favorable results and that influence the output volume; they must be defined well before the process.</p>
<ol>
<li>
<p><strong>Number of filters</strong>: Affects the depth of the output. For example, three distinct filters would produce three different feature maps, thus creating a depth of three. <em>Each filter acts as a specialized detector (contours, textures, shapes) and produces its own feature map; these maps stack to form the output depth.</em></p>
</li>
<li>
<p><strong>Stride</strong>: Is the distance, or number of pixels, over which the kernel moves across the input matrix. While stride values of two or more are rare, a larger stride produces a smaller output. <em>A stride of 1 means the filter moves pixel by pixel (detailed examination), while a stride of 2 skips one pixel with each movement (faster examination, smaller image).</em></p>
</li>
<li>
<p><strong>Zero-padding</strong>: Is generally used when filters do not match the input image. This zeros all elements located outside the input matrix, producing a larger or equal-sized output. Three padding types exist:</p>
<ul>
<li><strong>Valid padding:</strong> This is also called the absence of padding. In this case, the last convolution is abandoned if dimensions do not align. <em>(If the puzzle pieces don’t fit at the edge, they are abandoned)</em></li>
<li><strong>Same padding:</strong> This padding guarantees that the output layer has the same size as the input layer. <em>(Empty pieces are added around so everything fits perfectly)</em></li>
<li><strong>Full padding:</strong> This padding type increases the output size by adding zeros to the input border. <em>(Even more empty pieces are added to obtain a larger image)</em></li>
</ul>
</li>
</ol>
<p><strong>Following the convolution operation, the CNN immediately applies the ReLU function</strong> (<strong>Re</strong>ctified <strong>L</strong>inear <strong>U</strong>nit). This activation function acts as a selective filter that eliminates weak signals (negative values) to retain only significant activations (positive values).</p>
<img src="/Relu-activation-function.webp" alt="ReLU activation function"/>
<p><strong>Operational Principle:</strong></p>
<ul>
<li>Positive value → retained as is</li>
<li>Negative value → transformed to zero</li>
</ul>
<p><strong>Formula:</strong> ReLU(x) = max(0, x)</p>
<p><strong>Practical Example:</strong>
Feature map before ReLU: <code>[-2, 5, -1, 8, -3, 4]</code>
Feature map after ReLU: <code>[0, 5, 0, 8, 0, 4]</code></p>
<p><strong>Impact on Learning:</strong> The introduction of this non-linearity is crucial as it enables the network to model complex relationships between characteristics. Without ReLU, the CNN would be limited to linear transformations and could not detect sophisticated patterns such as spatial relationships between facial elements (eye-nose distance, mouth-cheek configuration) or other complex visual subtleties.</p>
<p>This step thus transforms a simple mathematical calculation into a genuine intelligent recognition process.</p>
<img src="/iclh-diagram-convolutional-neural-networks.png" alt="Convolutional neural networks diagram"/>
<h3 id="additional-convolutional-layer">Additional Convolutional Layer</h3>
<p>It is frequent that layer hierarchization is applied to progressively analyze the increasing complexity of an image. This cascade architecture enables the CNN structure to adapt intelligently: subsequent layers can exploit information from the receptive fields of preceding layers, thus creating a genuine detection hierarchy.</p>
<p><strong>Characteristic Hierarchy Principle:</strong></p>
<ul>
<li><strong>Initial layers</strong>: Detect low-level characteristics (contours, lines, simple textures)</li>
<li><strong>Intermediate layers</strong>: Combine these elements to identify more complex shapes (angles, curves, geometric patterns)</li>
<li><strong>Deep layers</strong>: Recognize specific object parts (wheels, handlebars, frames)</li>
<li><strong>Final layers</strong>: Assemble these parts to identify the complete object (bicycle, car, face)</li>
</ul>
<p><strong>Concrete Example:</strong> Consider bicycle recognition. The CNN proceeds in stages:</p>
<ol>
<li>Detection of circles and straight lines</li>
<li>Identification of circular shapes (potential wheels)</li>
<li>Recognition of handlebars and frame</li>
<li>Final association: “wheels + handlebars + frame = bicycle”</li>
</ol>
<p>This hierarchical approach enables the network to construct a progressive understanding of the image, where each layer refines and enriches the analysis of the previous one. Ultimately, the convolutional layer converts the image into structured numerical values, enabling the neural network to interpret and extract pertinent patterns for final classification.</p>
<img src="/hierarchy.png" alt="CNN characteristic hierarchy"/>
<h2 id="pooling-or-subsampling-layer-pooling-layer"><strong>Pooling or Subsampling Layer</strong> (<em>Pooling layer</em>)</h2>
<p>In this stage of the CNN process, the collected information is reduced and grouped to decrease data dimensionality. Following the same process as the convolutional layer, it applies a filter that, unlike the convolutional layer, has no weights. An aggregation function is applied to the receptive field values to populate the output array. <strong>This aggregation function constitutes the primary configurable parameter that determines the pooling type utilized.</strong></p>
<p><strong>Primary Objectives:</strong></p>
<ul>
<li>Reduce data size</li>
<li>Decrease the number of parameters</li>
<li>Preserve important characteristics</li>
</ul>
<p><strong>The two principal pooling types (aggregation functions):</strong></p>
<p><strong>1. Max Pooling:</strong></p>
<ul>
<li>Aggregation function: <code>f(region) = max(values)</code></li>
<li>Selects the <strong>maximum value</strong> in each receptive field region</li>
<li>Preserves the most salient characteristics</li>
<li>More commonly used as it preserves important contours and details</li>
</ul>
<p><strong>2. Average Pooling:</strong></p>
<ul>
<li>Aggregation function: <code>f(region) = average(values)</code></li>
<li>Calculates the <strong>arithmetic mean</strong> of all values in the receptive field</li>
<li>Smooths data by reducing noise</li>
<li>Less utilized but useful for certain specific applications</li>
</ul>
<h2 id="visualization">Visualization</h2>
<h4 id="22-region-organized-as-a-matrix">2×2 region organized as a matrix:</h4>
<img src="/Sans-titre-2025-06-23-2323 (2).png" alt="2x2 region organized as matrix"/>
<h2 id="calculations-according-to-pooling-type">Calculations according to pooling type:</h2>
<p><strong>Max Pooling:</strong></p>
<ul>
<li>We examine all values: <code>1, 3, 2, 4</code></li>
<li>We take the <strong>largest</strong>: <code>max(1, 3, 2, 4) = 4</code></li>
<li><strong>Result: 4</strong></li>
</ul>
<p><strong>Average Pooling:</strong></p>
<ul>
<li>We sum all values: <code>1 + 3 + 2 + 4 = 10</code></li>
<li>We divide by the number of values: <code>10 ÷ 4 = 2.5</code></li>
<li><strong>Result: 2.5</strong></li>
</ul>
<h2 id="process-visualization">Process Visualization:</h2>
<img src="/Sans-titre-2025-06-23-2323 (3).png" alt="Pooling process visualization"/>
<p>The pooling filter “examines” this 2×2 region and <strong>summarizes it into a single value</strong> according to the chosen aggregation function.</p>
<p>These parameters (aggregation function type, filter size, stride) are configurable before training according to the model’s specific needs, enabling adaptation of pooling behavior to the targeted classification task.</p>
<h2 id="fully-connected-layer-fully-connected-layer"><strong>Fully Connected Layer</strong> (<em>Fully connected layer</em>)</h2>
<p>This layer performs classification based on characteristics extracted from previous layers and their filters. It applies an activation function (generally <strong>softmax</strong>) that enables data conversion to <strong>probabilities</strong>: each possible class receives a score between 0 and 1, and the <strong>sum of all probabilities equals 1</strong>.</p>
<h3 id="example">Example:</h3>
<p>For animal recognition:</p>
<ul>
<li>Cat: 0.7 (70% probability)</li>
<li>Dog: 0.2 (20% probability)</li>
<li>Bird: 0.1 (10% probability)</li>
<li><strong>Total: 0.7 + 0.2 + 0.1 = 1.0</strong></li>
</ul>
<p>The class with the <strong>highest probability</strong> (here “Cat” with 0.7) is the final prediction.</p>
<h2 id="conclusion">Conclusion</h2>
<p><strong>Convolutional Neural Networks</strong> (CNNs) constitute a particularly effective deep learning architecture for image processing and analysis. Their operation relies on three principal components: convolutional layers that extract characteristics, pooling layers that reduce dimensionality, and fully connected layers that perform final classification.</p>
<h3 id="architecture-and-performance">Architecture and Performance</h3>
<p>This hierarchical structure enables CNNs to progressively detect increasingly complex patterns, from simple contours to complete objects. Configurable hyperparameters (number of filters, stride, padding) offer adaptation flexibility according to the specific needs of each application.</p>
<h3 id="practical-applications">Practical Applications</h3>
<p>CNNs currently find concrete applications in numerous sectors: medical diagnosis through imaging, automated surveillance systems, industrial quality control, and autonomous vehicles. Their capacity to efficiently process large quantities of visual data makes them an indispensable tool for these domains.</p>
<h3 id="technical-perspectives">Technical Perspectives</h3>
<p>The continuous optimization of CNN architectures, combined with improved computational capabilities, enables envisioning more complex applications and increased precision in image recognition tasks. Understanding these fundamental mechanisms remains essential for effectively developing and implementing these technological solutions.</p>  </div>  <style>astro-island,astro-slot,astro-static-slot{display:contents}</style><script>(()=>{var e=async t=>{await(await t())()};(self.Astro||(self.Astro={})).load=e;window.dispatchEvent(new Event("astro:load"));})();</script><script>(()=>{var A=Object.defineProperty;var g=(i,o,a)=>o in i?A(i,o,{enumerable:!0,configurable:!0,writable:!0,value:a}):i[o]=a;var d=(i,o,a)=>g(i,typeof o!="symbol"?o+"":o,a);{let i={0:t=>m(t),1:t=>a(t),2:t=>new RegExp(t),3:t=>new Date(t),4:t=>new Map(a(t)),5:t=>new Set(a(t)),6:t=>BigInt(t),7:t=>new URL(t),8:t=>new Uint8Array(t),9:t=>new Uint16Array(t),10:t=>new Uint32Array(t),11:t=>1/0*t},o=t=>{let[l,e]=t;return l in i?i[l](e):void 0},a=t=>t.map(o),m=t=>typeof t!="object"||t===null?t:Object.fromEntries(Object.entries(t).map(([l,e])=>[l,o(e)]));class y extends HTMLElement{constructor(){super(...arguments);d(this,"Component");d(this,"hydrator");d(this,"hydrate",async()=>{var b;if(!this.hydrator||!this.isConnected)return;let e=(b=this.parentElement)==null?void 0:b.closest("astro-island[ssr]");if(e){e.addEventListener("astro:hydrate",this.hydrate,{once:!0});return}let c=this.querySelectorAll("astro-slot"),n={},h=this.querySelectorAll("template[data-astro-template]");for(let r of h){let s=r.closest(this.tagName);s!=null&&s.isSameNode(this)&&(n[r.getAttribute("data-astro-template")||"default"]=r.innerHTML,r.remove())}for(let r of c){let s=r.closest(this.tagName);s!=null&&s.isSameNode(this)&&(n[r.getAttribute("name")||"default"]=r.innerHTML)}let p;try{p=this.hasAttribute("props")?m(JSON.parse(this.getAttribute("props"))):{}}catch(r){let s=this.getAttribute("component-url")||"<unknown>",v=this.getAttribute("component-export");throw v&&(s+=` (export ${v})`),console.error(`[hydrate] Error parsing props for component ${s}`,this.getAttribute("props"),r),r}let u;await this.hydrator(this)(this.Component,p,n,{client:this.getAttribute("client")}),this.removeAttribute("ssr"),this.dispatchEvent(new CustomEvent("astro:hydrate"))});d(this,"unmount",()=>{this.isConnected||this.dispatchEvent(new CustomEvent("astro:unmount"))})}disconnectedCallback(){document.removeEventListener("astro:after-swap",this.unmount),document.addEventListener("astro:after-swap",this.unmount,{once:!0})}connectedCallback(){if(!this.hasAttribute("await-children")||document.readyState==="interactive"||document.readyState==="complete")this.childrenConnectedCallback();else{let e=()=>{document.removeEventListener("DOMContentLoaded",e),c.disconnect(),this.childrenConnectedCallback()},c=new MutationObserver(()=>{var n;((n=this.lastChild)==null?void 0:n.nodeType)===Node.COMMENT_NODE&&this.lastChild.nodeValue==="astro:end"&&(this.lastChild.remove(),e())});c.observe(this,{childList:!0}),document.addEventListener("DOMContentLoaded",e)}}async childrenConnectedCallback(){let e=this.getAttribute("before-hydration-url");e&&await import(e),this.start()}async start(){let e=JSON.parse(this.getAttribute("opts")),c=this.getAttribute("client");if(Astro[c]===void 0){window.addEventListener(`astro:${c}`,()=>this.start(),{once:!0});return}try{await Astro[c](async()=>{let n=this.getAttribute("renderer-url"),[h,{default:p}]=await Promise.all([import(this.getAttribute("component-url")),n?import(n):()=>()=>{}]),u=this.getAttribute("component-export")||"default";if(!u.includes("."))this.Component=h[u];else{this.Component=h;for(let f of u.split("."))this.Component=this.Component[f]}return this.hydrator=p,this.hydrate},e,this)}catch(n){console.error(`[astro-island] Error hydrating ${this.getAttribute("component-url")}`,n)}}attributeChangedCallback(){this.hydrate()}}d(y,"observedAttributes",["props"]),customElements.get("astro-island")||customElements.define("astro-island",y)}})();</script><astro-island uid="Z1C2Mm7" component-url="/_astro/Outline.dcg6D8k3.js" component-export="Outline" renderer-url="/_astro/client.ACrJIrlS.js" props="{&quot;data-astro-cid-fv4hxrc2&quot;:[0,true]}" ssr client="load" opts="{&quot;name&quot;:&quot;Outline&quot;,&quot;value&quot;:true}" await-children><div class="relative w-max hidden md:block lg:block"><div class="fixed inset-y-0 right-0 z-40 w-10 "></div><div class="fixed top-[40%] z-50 right-5 pointer-events-none"><div data-strength="45" data-strength-text="25" class="magnetic pointer-events-auto"><div class="relative flex flex-col items-center rounded-lg gap-3 p-3 hover:bg-[var(--secondary)]/30"></div></div></div></div><!--astro:end--></astro-island> </div> </section>  </div> <footer class="medium text-[0.7rem] uppercase" data-astro-cid-bbsqf2va> <div class="grid-footer" data-astro-cid-bbsqf2va> <div class="left" data-astro-cid-bbsqf2va> <div class="flex flex-col gap-2 lg:gap-8 justify-between items-start lg:grid grid-cols-5" data-astro-cid-bbsqf2va> <span class="lg:col-span-3" data-astro-cid-bbsqf2va> Trained as a network and telecom engineer, I have developed complementary expertise in software infrastructure and development. </span> <div class="legacy lg:row-start-2" data-astro-cid-bbsqf2va> <span class="declaration" data-astro-cid-bbsqf2va>
Copyright © <span id="footer-year" data-astro-cid-bbsqf2va></span> elysee Mboussa . All rights reserved.</span> </div> </div> </div> <div class="contacts lg:row-start-1 lg:col-span-4" data-astro-cid-bbsqf2va> <div class="btn-fixed" data-astro-cid-bbsqf2va> <div class="btn btn-round" data-astro-cid-bbsqf2va> <a href="mailto:contact@eembouz.com" class="btn-click magnetic " data-strength="100" data-strength-text="50" data-astro-cid-bbsqf2va> <div class="btn-fill" data-astro-cid-bbsqf2va></div> <span style="text-align: center;" class="btn-text" data-astro-cid-bbsqf2va> <span class="btn-text-inner" data-astro-cid-bbsqf2va> Get in touch </span> </span> </a> </div> </div> </div> <div class="right" data-astro-cid-bbsqf2va> <div class="uppercase" data-astro-cid-bbsqf2va> <div class="flex flex-col gap-2" data-astro-cid-bbsqf2va> <h4 data-astro-cid-bbsqf2va>Networking</h4>
              <ul class="flex flex-col gap-2 text-sm" data-astro-cid-bbsqf2va> <a href="https://github.com/elyseeMB" data-astro-cid-bbsqf2va> <li data-astro-cid-bbsqf2va>Github</li> </a><a href="https://www.linkedin.com/in/%CE%BEmmanuelito-mboussa-49099932a?utm_source=share&utm_campaign=share_via&utm_content=profile&utm_medium=ios_app" data-astro-cid-bbsqf2va> <li data-astro-cid-bbsqf2va>Linkedin</li> </a><a href="https://umami-proxy.mboussaemmanuelito.workers.dev/share/nctiJRtBLbtlHzc0" data-astro-cid-bbsqf2va> <li data-astro-cid-bbsqf2va>Statistics</li> </a> </ul> </div> </div> </div> </div> </footer>  <script type="module" src="/_astro/Footer.astro_astro_type_script_index_0_lang.Bsq0Z681.js"></script> <meta name="astro-view-transitions-enabled" content="true"><meta name="astro-view-transitions-fallback" content="animate"><script type="module" src="/_astro/ClientRouter.astro_astro_type_script_index_0_lang.CWs-ObRl.js"></script> <script type="module">const i=["en"];function l(t,n){if(n.length!==1)throw new Error("Char must be single character");if(t==null||t.length===0)return t;const a=n.charCodeAt(0);let e=0,r=t.length-1;for(;e<=r&&t.charCodeAt(e)===a;)e++;for(;r>=e&&t.charCodeAt(r)===a;)r--;return t.slice(e,r+1)}function c(){const t=localStorage.getItem("lang"),n=window.location.pathname,a=navigator.language.split("-")[0].toLowerCase(),e=n.split("/")[1];if(i.includes(e)&&e!=="fr"){localStorage.setItem("lang",e);return}if(t){t!=="fr"&&!n.startsWith("/"+t)&&(window.location.href="/"+l(t+n,"/"));return}let o="fr";i.includes(a)?o=a:a!=="fr"&&(o="en"),localStorage.setItem("lang",o),o!=="fr"&&!n.startsWith("/"+o)&&(window.location.href="/"+l(o+n,"/"))}c();</script> </body></html>  <script type="module">const s=Array.from(document.querySelectorAll("h2")),n=document.getElementById("mindmap");let t=[];const d=()=>{t.forEach(e=>e.disconnect()),t=[],s.forEach(e=>{const c=new IntersectionObserver(o=>{const r=o[0];r.isIntersecting&&(n.dataset.target=r.target.id,n.dispatchEvent(new CustomEvent("mindmap",{detail:r.target.id})))});c.observe(e),t.push(c)})};n.addEventListener("click",d);n?.addEventListener("beforeunload",()=>{t.forEach(e=>e.disconnect())});</script>